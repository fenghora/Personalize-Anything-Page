<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="Personalize Anything is a training-free framework for personalized image generation in DiT, enabling layout-guided generation, multi-subject personalization, and mask-controlled editing." />
    <meta
      name="keywords"
      content="Subject personalization, T2I Image Generation, Diffusion Models" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Personalize Anything for Free with Diffusion Transformer</title>

    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet" />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="./static/css/academicons.min.css" />
    <link rel="stylesheet" href="./static/css/index.css" />
    <!-- <link rel="icon" href="./static/images/favicon.svg" /> -->

    <style>
      .render_wrapper {
        position: relative;
        height: 350px;
      }

      .conference {
        font-family: "Google Sans", sans-serif;
        color: hsl(240, 2%, 10%) !important;
        font-family: "Merriweather", serif;
        font-weight: 500;
      }

      .results-carousel textbox {
        font-size: 7px;
        font-family: "Google Sans", cursive, sans-serif;
        color: hsl(321, 56%, 56%) !important;
      }
      .dialog-box {
        background-color: rgba(255, 255, 255, 0.5);
        border: 1px solid rgba(96, 85, 85, 0.494);
        padding: 10px;
        border-radius: 15px;
        z-index: 1000;
        font-size: 14px;
        font-family: "Comic Sans MS", cursive, sans-serif;
        color: hsl(322, 33%, 22%) !important;
        font-weight: bold;
      }
    </style>

    <!-- Import the component -->
    <script
      type="module"
      src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.1.1/model-viewer.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"></script>
  </head>
  <body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a
          role="button"
          class="navbar-burger"
          aria-label="menu"
          aria-expanded="false">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>

      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center">
          <a class="navbar-item" href="https://github.com/fenghora">
            <span class="icon">
              <i class="fas fa-home"></i>
            </span>
          </a>

          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link"> More Research </a>
            <div class="navbar-dropdown">
              <a
                class="navbar-item"
                href="https://huanngzh.github.io/Parts2Whole/"
                target="_blank">
                Parts2Whole
              </a>
            </div>
          </div>
        </div>
      </div>
    </nav>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                Personalize Anything for Free with Diffusion Transformer
              </h1>
              <div class="is-size-5 publication-authors">
                <a
                  href="https://scholar.google.com/citations?user=riCXH64AAAAJ"
                  target="_blank"
                  >Haoran Feng</a
                ><sup>1*</sup>,
                <a
                  href="https://scholar.google.com.hk/citations?user=U3VbX6kAAAAJ"
                  target="_blank"
                  >Zehuan Huang</a
                ><sup>2*†</sup>,
                <a
                  href="https://scholar.google.com/citations?user=HL3uwegAAAAJ"
                  target="_blank"
                  >Lin Li</a
                ><sup>3</sup>,
                <a href="https://lucassheng.github.io/" target="_blank"
                  >Lu Sheng</a
                ><sup>2✉</sup>
              </div>

              <div class="is-size-5 publication-authors">
                <sup>1</sup>Tsinghua Shenzhen International Graduate School
                &nbsp;&nbsp; <sup>2</sup>School of Software, Beihang University
                &nbsp;&nbsp; <br />
                <sup>3</sup>School of Finance, Renmin University of China
                &nbsp;&nbsp; <br />
                <sup>*</sup>Equal contribution &nbsp;&nbsp;<sup>†</sup>Project
                Lead &nbsp;&nbsp; <sup>✉</sup>Corresponding Authors
              </div>

            <div class="x-center-text" style="font-size: 20px; font-weight: 700; color: #5f5f5f;">
                AAAI 2026 Poster
            </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a
                      href="https://arxiv.org/abs/2503.12590"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>
                  <!-- Code Link. -->
                  <span class="link-block">
                    <a
                      href="https://github.com/fenghora/personalize-anything"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <!-- Model Link. -->
                  <!-- <span class="link-block">
                    <a
                      href="https://huggingface.co/huanngzh/mv-adapter"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fa fa-database"></i>
                      </span>
                      <span>Model</span>
                    </a>
                  </span> -->
                  <!-- Demo Link. -->
                  <!-- <span class="link-block">
                    <a
                      href="https://huggingface.co/collections/huanngzh/mv-adapter-spaces-677e497578747fd734a1b999"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="far fa-smile"></i>
                      </span>
                      <span>Demos</span>
                    </a>
                  </span> -->
                </div>
              </div>
              <div class="is-size-5 publication-authors">
                <hr
                  style="
                    width: 100%;
                    height: 0.7px;
                    background-color: rgba(0, 0, 0, 0.665);
                    margin-top: 1em;
                  " />
                Customize any subject with advanced DiT without additional
                fine-tuning.
              </div>
              <div style="padding-top: 1.5rem">
                <img src="./images/pr.png" class="" alt="" />
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-light is-small">
      <div class="hero-body">
        <div class="container is-centered">
          <div class="has-text-centered">
            <img src="./images/teaser.png" class="" alt="" width="80%" />
            <!-- <video
              id="dollyzoom"
              autoplay
              controls
              muted
              loop
              playsinline
              width="80%">
              <source src="./videos/teaser.mp4" type="video/mp4" />
            </video> -->
          </div>
          <div class="columns is-centered">
            <div class="column is-four-fifths">
              The images show our method's results in single-subject
              personalization, layout-guided subject personalization,
              multi-subject personalization, and more, demonstrating strong
              identity preservation and versatility.
              <!-- <b>Row 1</b> shows results of our method in
              <font color="#3a86ff"
                ><b
                  >single-subject personalization</b
                ></font
              > and 
              <font color="#3a86ff"
                ><b
                  >layout-guided subject personalization</b
                ></font
              >. -->
              <!-- <b>Row 1</b> shows results by integrating MV-Adapter with
              <font color="#3a86ff"
                ><b
                  >personalized T2Is, distilled few-step T2Is, and
                  ControlNets</b
                ></font
              >, demonstrating its adaptability. <b>Row 2</b> shows results
              under various control signals, including
              <font color="#3a86ff"
                ><b>view-guided or geometry-guided</b>
              </font>
              generation with
              <font color="#3a86ff"><b>text or image inputs</b></font
              >, showcasing its versatility. -->
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <video
              id="dollyzoom"
              autoplay
              controls
              muted
              loop
              playsinline
              width="100%">
              <source src="./videos/more_views.mp4" type="video/mp4" />
            </video>
            <br />
            <div class="has-text-centered">
              Here we show that MV-Adapter generates viewpoints with elevation
              ranging from 0 to 30 degrees.
            </div>
          </div>
        </div>
      </div>
    </section> -->

    <section class="section">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Personalized image generation aims to produce images of
                user-specified concepts while enabling flexible editing. Recent
                training-free approaches, while exhibit higher computational
                efficiency than training-based methods, struggle with identity
                preservation, applicability, and compatibility with diffusion
                transformers (DiTs). In this paper, we uncover the untapped
                potential of DiT, where simply replacing denoising tokens with
                those of a reference subject achieves zero-shot subject
                reconstruction. This simple yet effective feature injection
                technique unlocks diverse scenarios, from personalization to
                image editing. Building upon this observation, we propose
                <b>Personalize Anything</b>, a training-free framework that
                achieves personalized image generation in DiT through: (1)
                timestep-adaptive token replacement that enforces subject
                consistency via early-stage injection and enhances flexibility
                through late-stage regularization, and (2) patch perturbation
                strategies to boost structural diversity. Our method seamlessly
                supports layout-guided generation, multi-subject
                personalization, and mask-controlled editing. Evaluations
                demonstrate state-of-the-art performance in identity
                preservation and versatility. Our work establishes new insights
                into DiTs while delivering a practical paradigm for efficient
                personalization.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="has-text-centered">
          <h2 class="title is-3">Method</h2>
        </div>
        <br />
        <div class="columns is-centered">
          <div class="column is-full-width">
            <!-- <div class="column is-half">
              <img src="./assets/overview_inference.png" class="" alt="" />
            </div> -->
            <div>
              <img src="./images/pipeline.png" class="" alt="" />
            </div>
            <!-- <div class="column is-half">
              MV-Adapter is a plug-and-play adapter that learns multi-view priors
              transferable to derivatives of T2I models without
              <font color="#3a86ff"><b>specific tuning</b></font
              >, and enable T2Is to generate multi-view consistent images
              <font color="#3a86ff"><b>under various conditions</b></font
              >. At inference time, our MV-Adapter, which contains a condition
              guider <font color="#ffe699"><b>(yellow)</b></font> and the
              decoupled attention layers <font color="#bdd7ee"><b>(blue)</b></font
              >, can be directly inserted into a personalized or distilled T2I to
              constitute the multi-view generator.
            </div> -->
            <div>
              Personalize Anything anchors subject identity in early denoising
              through
              <font color="#3a86ff"><b>mask-guided token replacement</b></font>
              with preserved positional encoding, and transitions to multi-modal
              attention for semantic fusion with text in later steps. During
              token replacement, we inject variations via
              <font color="#3a86ff"><b>patch perturbations</b></font
              >. This timestep-adaptive strategy balances identity preservation
              and generative flexibility.
            </div>
          </div>
        </div>
        <div class="columns is-centered">
          <div class="column is-full-width">
            <br />
            <img src="./images/method_extensions.png" class="" alt="" />
            Our method enables: (a)
            <font color="#3a86ff"><b>layout-guided generation</b></font> by
            translating token-injected regions, (b)
            <font color="#3a86ff"><b>multi-subject composition</b></font>
            through sequential token injection, and (c)
            <font color="#3a86ff"><b>inpainting</b></font> and
            <font color="#3a86ff"><b>outpainting</b></font>
            via specifying masks and increased replacement.
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">
                Qualitative Comparisons on Single-subject Personalization
              </h2>
            </div>
            <br />
            <img src="./images/comparison_single_subject.png" class="" alt="" />
            <!-- <video autoplay controls muted loop playsinline height="100%">
              <source src="./videos/more_results_t2mv.mp4" type="video/mp4" />
            </video> -->
            <div>
              Our method produces high-fidelity images that are highly
              consistent with the specified subjects, without necessitating
              training or fine-tuning.
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">
                Qualitative Comparisons on Multi-subject Personalization
              </h2>
            </div>
            <br />
            <img src="./images/comparison_multi_subject.png" class="" alt="" />
            <!-- <video autoplay controls muted loop playsinline height="100%">
              <source src="./videos/more_results_i2mv.mp4" type="video/mp4" />
            </video> -->
            <div>
              Our method manages to maintain natural interactions among subjects
              via layout-guided generation, while ensuring each subject retains
              its identical characteristics and distinctiveness.
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">Qualitative Comparisons on Subject-scene Composition</h2>
            </div>
            <br />
            <img src="./images/comparison_subject_scene.png" class="" alt="" width="60%"/>
            <div>
            Our method successfully generates natural images while effectively preserving the details of the subjects.
            </div> -->
    <!-- <video autoplay controls muted loop playsinline height="100%">
              <source
                src="./videos/more_results_sketch2mv.mp4"
                type="video/mp4" />  
            </video> -->
    <!-- </div>
        </div>
      </div>
    </section> -->

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">More Applications</h2>
            </div>
            <br />
            <img src="./images/applications.png" class="" alt="" />
            <div>
              Our method naturally extends to diverse real-world applications,
              including subject-driven image generation with layout guidance,
              inpainting and outpainting.
            </div>
            <!-- <video autoplay controls muted loop playsinline height="100%">
              <source
                src="./videos/more_results_text_to_3d.mp4"
                type="video/mp4" />
            </video> -->
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">Ablation Study</h2>
            </div>
            <br />
            <img src="./images/ablation_study.png" class="" alt="" />
            <!-- <video autoplay controls muted loop playsinline height="100%">
              <source
                src="./videos/more_results_image_to_3d.mp4"
                type="video/mp4" />
            </video> -->
            <div>
              We conduct ablation studies on single-subject personalization,
              examining the effects of token replacement timestep threshold \(
              \tau \) and the patch perturbation strategy.
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="has-text-centered">
          <h2 class="title">BibTeX</h2>
        </div>
        <div
          class="columns is-centered has-text-centered"
          style="padding-bottom: 1.5rem">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <pre><code>@article{feng2025personalize,
  title={Personalize Anything for Free with Diffusion Transformer},
  author={Feng, Haoran and Huang, Zehuan and Li, Lin and Lv, Hairong and Sheng, Lu},
  journal={arXiv preprint arXiv:2503.12590},
  year={2025}
}</code></pre>
            </div>
          </div>
        </div>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <div class="content has-text-centered">
          <!-- <a class="icon-link" href="">
            <i class="fas fa-file-pdf"></i>
          </a> -->
          <a
            class="icon-link"
            href="https://github.com/fenghora"
            class="external-link"
            disabled>
            <i class="fab fa-github"></i>
          </a>
        </div>
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p style="text-align: center">
                Source code of this page can be found at
                <a
                  href="https://github.com/DHUAVY/Personalize-Anything-Page"
                  target="_blank"
                  >Personalize-Anything-Page</a
                >. The website template is forked from
                <a
                  href="https://github.com/huanngzh/MV-Adapter-Page"
                  target="_blank"
                  >MV-Adapter-Page</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
